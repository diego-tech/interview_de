{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e2f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "from sqlalchemy import create_engine, text\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9300772",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWSAPI_KEY = \"6868caa0dca245aab75051aaf8b7f518\"\n",
    "API_URL = \"https://newsapi.org/v2/everything\"\n",
    "DATABASE_URL = \"postgresql://postgres.xyzgfwktosydyrzawozi:DmH171200.@aws-0-eu-west-3.pooler.supabase.com:5432/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2545dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0d8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_term(t: str) -> str:\n",
    "    \"\"\"\n",
    "    Si el término contiene espacios, lo envuelve entre comillas y elimina espacios.\n",
    "    Esto asegura búsquedas exactas en NewsAPI.\n",
    "    \"\"\"\n",
    "    t = t.strip()\n",
    "    return f'\"{t}\"' if \" \" in t else t\n",
    "\n",
    "def chunk_list(lst: List[str], max_len: int) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Divide la lista de términos en sublistas cuya longitud total\n",
    "    (en caracteres) no exceda max_len.\n",
    "    Esto evita que el parámetro `q` supere los 500 caracteres en NewsAPI (Error identificado The complete value for q must be URL-encoded. Max length: 500 chars.).\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current = []\n",
    "    length = 0\n",
    "\n",
    "    for item in lst:\n",
    "        token = quote_term(item)\n",
    "        token_len = len(token) + 4  # Contamos \" OR \" como 4 caracteres\n",
    "        if length + token_len > max_len and current:\n",
    "            chunks.append(current)\n",
    "            current = [item]\n",
    "            length = token_len\n",
    "        else:\n",
    "            current.append(item)\n",
    "            length += token_len\n",
    "\n",
    "    if current:\n",
    "        chunks.append(current)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def build_blocks_by_category(groups: Dict[str, List[str]], max_chars: int, categories: List[str] = None) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Prepara bloques (OR-clauses) por categoría aplicando chunking para no superar el límite de caracteres.\n",
    "    - groups: dict {categoria: [terminos ya quoteados y con NOT si procede]}\n",
    "    - max_chars: límite total del parámetro q (NewsAPI = 500)\n",
    "    - categories: orden explícito de categorías a usar (si None, usa todas las keys de groups)\n",
    "    Devuelve un dict {categoria: [ \"(t1 OR t2 ...)\", \"(...)\" , ... ]}\n",
    "    \"\"\"\n",
    "    if categories is None:\n",
    "        categories = list(groups.keys())\n",
    "    if not categories:\n",
    "        raise ValueError(\"No hay categorías para construir la query.\")\n",
    "\n",
    "    # Estimación simple: repartimos el presupuesto entre categorías\n",
    "    per_cat_budget = max(50, max_chars // max(1, len(categories)))  # mínimo 50 por bloque/categoría\n",
    "\n",
    "    blocks = {}\n",
    "    for cat in categories:\n",
    "        terms = groups.get(cat, [])\n",
    "        if not terms:\n",
    "            raise ValueError(f\"No hay términos activos para la categoría '{cat}'.\")\n",
    "\n",
    "        # Partimos la lista de términos de esta categoría en trozos que quepan en su presupuesto\n",
    "        cat_chunks = chunk_list(terms, per_cat_budget)\n",
    "        cat_blocks = [ \"(\" + \" OR \".join(chunk) + \")\" for chunk in cat_chunks ]\n",
    "        blocks[cat] = cat_blocks\n",
    "\n",
    "    return blocks\n",
    "\n",
    "def build_queries_from_blocks(\n",
    "    blocks_by_cat: Dict[str, List[str]],\n",
    "    max_chars: int,\n",
    "    categories: List[str]\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Combina un bloque por categoría con AND (producto cartesiano) y filtra\n",
    "    las combinaciones que superen 'max_chars'.\n",
    "    \"\"\"\n",
    "    if not categories:\n",
    "        categories = list(blocks_by_cat.keys())\n",
    "\n",
    "    queries: List[str] = []\n",
    "    for combo in product(*[blocks_by_cat[cat] for cat in categories]):\n",
    "        q = \" AND \".join(combo)\n",
    "        if len(q) <= max_chars:\n",
    "            queries.append(q)\n",
    "    if not queries:\n",
    "        raise ValueError(\"No se pudo generar ninguna query <= max_chars; reduce términos o ajusta el reparto.\")\n",
    "    return queries\n",
    "\n",
    "def build_q_from_db(max_chars: int = 500, categories: List[str] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Lee keywords activas desde la BD y construye una o varias queries <= max_chars\n",
    "    usando bloques por categoría y combinándolos con AND.\n",
    "    - max_chars: límite del parámetro `q` (NewsAPI = 500)\n",
    "    - categories: orden/selección de categorías a usar (por defecto, todas las encontradas)\n",
    "    Devuelve: lista de strings `q` listas para usar en /v2/everything.\n",
    "    \"\"\"\n",
    "    sql = \"\"\"\n",
    "    SELECT term, category, negate\n",
    "    FROM news_keywords\n",
    "    WHERE active = TRUE\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Leer términos y agrupar por categoría, dejando cada término \"listo\" (quoted y con NOT si aplica)\n",
    "    groups: Dict[str, List[str]] = defaultdict(list)\n",
    "    with engine.connect() as conn:\n",
    "        for term, category, negate in conn.execute(text(sql)):\n",
    "            token = quote_term(term.strip())\n",
    "            token = f'NOT {token}' if negate else token\n",
    "            groups[category].append(token)\n",
    "\n",
    "    if not groups:\n",
    "        raise ValueError(\"No hay keywords activas en la base de datos.\")\n",
    "\n",
    "    # 2) Si no se especifica orden/conjunto de categorías, usamos todas las presentes\n",
    "    cats_order = categories or list(groups.keys())\n",
    "\n",
    "    # 3) Construir bloques por categoría con chunking interno\n",
    "    blocks_by_cat = build_blocks_by_category(groups, max_chars=max_chars, categories=cats_order)\n",
    "\n",
    "    # 4) Combinar bloques (producto cartesiano) asegurando q <= max_chars\n",
    "    queries = build_queries_from_blocks(blocks_by_cat, max_chars=max_chars, categories=cats_order)\n",
    "\n",
    "    if not queries:\n",
    "        raise ValueError(\"No se pudo construir ninguna query dentro del límite de caracteres.\")\n",
    "\n",
    "    return queries\n",
    "\n",
    "def fetch_ai_marketing_news(api_url: str, params: dict) -> Tuple[Optional[pd.DataFrame], dict]:\n",
    "    \"\"\"\n",
    "    Llama a la API de NewsAPI para obtener noticias de AI y Marketing.\n",
    "    \n",
    "    Args:\n",
    "        api_url (str): URL base del endpoint (ej: https://newsapi.org/v2/everything).\n",
    "        api_key (str): Clave API de NewsAPI.\n",
    "        query (str): Query ya construida (ej: \"(AI terms) AND (Marketing terms)\").\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Optional[pd.DataFrame], dict]:\n",
    "            - DataFrame con artículos o None si hay error.\n",
    "            - Diccionario con metadatos de la respuesta (status, totalResults, error_message si aplica).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(api_url, params=params, timeout=10)\n",
    "        response.raise_for_status()  # Lanza excepción si el status HTTP != 200\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None, {\"status\": \"error\", \"error_message\": f\"Error de conexión: {str(e)}\"}\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except ValueError:\n",
    "        return None, {\"status\": \"error\", \"error_message\": \"La respuesta no es un JSON válido.\"}\n",
    "\n",
    "    status = data.get(\"status\", \"error\")\n",
    "    if status != \"ok\":\n",
    "        return None, {\n",
    "            \"status\": status,\n",
    "            \"error_message\": data.get(\"message\", \"Error desconocido en la API.\")\n",
    "        }\n",
    "\n",
    "    total_results = data.get(\"totalResults\", 0)\n",
    "    articles = data.get(\"articles\", [])\n",
    "\n",
    "    if not articles:\n",
    "        return pd.DataFrame(), {\"status\": status, \"totalResults\": total_results}\n",
    "\n",
    "    # Normalizamos a DataFrame\n",
    "    news_df = pd.json_normalize(articles)\n",
    "    news_df = news_df.rename(columns={\n",
    "        \"source.id\": \"source_id\",\n",
    "        \"source.name\": \"source_name\"\n",
    "    })\n",
    "\n",
    "    return news_df, {\"status\": status, \"totalResults\": total_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "839f8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza la API de News API para obtener las últimas noticias sobre Inteligencia Artificial\n",
    "# (AI) y Marketing. Necesitamos noticias que aborden ambos temas en su contenido.\n",
    "params = {\n",
    "    \"apiKey\": NEWSAPI_KEY,\n",
    "    \"q\":  build_q_from_db()\n",
    "}\n",
    "response = requests.get(API_URL, params=params)\n",
    "data = response.json()\n",
    "\n",
    "status = data.get(\"status\", {})\n",
    "res_len = data.get(\"totalResults\", {})\n",
    "news_df = pd.json_normalize(data.get(\"articles\", []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"apiKey\": NEWSAPI_KEY,\n",
    "    \"q\": build_q_from_db()\n",
    "}\n",
    "\n",
    "df, meta = fetch_ai_marketing_news(API_URL, params)\n",
    "\n",
    "if meta[\"status\"] == \"ok\":\n",
    "    print(f\"Noticias obtenidas: {meta['totalResults']}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Error: {meta.get('error_message')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
